<!-- Autogenerated by mlir-tblgen; don't manually edit -->
# 'tf_executor' Dialect


    The TensorFlow Executor dialect.

    This dialect models the TensorFlow executor semantics and can represent
    arbitrary TensorFlow graphs. As such it follows the existing execution model
    that includes deadness propagation, concurrent semantics, and control
    dependencies.

    Operations in this dialect return a value of type `!tf_executor.control` as
    last returned value (exceptions are `tf_executor.NextIteration.graph`,
    `tf_executor.NextIteration.sink` and `tf_executor.fetch` which don’t return any
    value).

[TOC]

## Operation definition

### `tf_executor.ControlTrigger` (::mlir::tf_executor::ControlTriggerOp)


    The `tf_executor.ControlTrigger` operation is similar to a no-op except that
    it always produces a valid output even when inputs are dead.
  


Syntax:

```
operation ::= `tf_executor.ControlTrigger` $controlInputs attr-dict
```


    Its primary use so far is in the scheduling of recvs, where we add
    ControlTrigger nodes and use them to trigger recvs. We allow ControlTrigger
    nodes to be enabled by dead nodes.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`control` | control

### `tf_executor.Enter` (::mlir::tf_executor::EnterOp)


    The "tf_executor.Enter" operation forwards its input to Tensorflow while
    loop.
  


    More details can be found in Tensorflow Control Flow white paper:
    https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

    Each tensor needs its own tf_executor.Enter to be made available inside a
    while loop.

    This is defined in Tensorflow as:

    REGISTER_OP("Enter")
       .Input("data: T")
       .Output("output: T")
       .Attr("T: type")
       .Attr("frame_name: string")
       .Attr("is_constant: bool = false")
       .Attr("parallel_iterations: int = 10")

    For example:
       %res:2 = tf_executor.Enter %arg0 frame "some/frame" parallel_iterations 42 constant : tensor<*xf32>

    Note: Additional result corresponds to the control output.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`frame_name` | ::mlir::StringAttr | string attribute
`is_constant` | ::mlir::BoolAttr | bool attribute
`parallel_iterations` | ::mlir::IntegerAttr | 64-bit signless integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`data` | any type
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | any type
`control` | control

### `tf_executor.Exit` (::mlir::tf_executor::ExitOp)


    The "tf_executor.Exit" operation forwards a value from an while loop to its
    consumer outside of loop. Each returned tensor needs its own
    tf_executor.Exit.
  


    More details can be found in Tensorflow Control Flow white paper:
    https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

    This is defined in Tensorflow as:

    REGISTER_OP("Exit")
       .Input("data: T")
       .Output("output: T")
       .Attr("T: type")

    For example:
     %1:2 = tf_executor.Exit %0#0 : tensor<*xi32> {T: "tfdtype$DT_INT32"}

    Note: Additional result corresponds to the control output.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`data` | any type
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | any type
`control` | control

### `tf_executor.fetch` (::mlir::tf_executor::FetchOp)


    The `tf_executor.fetch` operation terminates the graph and returns values;
  


Syntax:

```
operation ::= `tf_executor.fetch` ($fetches^ `:` type($fetches))? attr-dict
```


    The non-control operands of the fetch operation are returned outside of the
    graph and must match the return type of the graph.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`fetches` | any type

### `tf_executor.graph` (::mlir::tf_executor::GraphOp)

The `tf_executor.graph` operation contains a region with a
    single block that lists the operations in a TensorFlow graph.


    The operations are topologically sorted in-order (no cycles are allowed in
    the values). The execution model for operations in this block follows the
    TensorFlow executor semantics:
      1. Operations that don’t have any transitive dependencies through the
         def/use chains may be executed in parallel
         (`tf_executor.NextIteration.Source` is the exception).
      2. SSA values in this block can be implicitly dead. This means that every
         SSA value defined in a `tf_executor.graph` can be considered implicitly
         wrapped in a conceptual `dead_or<T>` structure, and includes a runtime
         flag indicating if the value is dead or present.
      3. Operations may have special case handling of dead values.

    The `tf_executor.graph` op only allows specific `tf_executor` dialect
    operations in its body: the `tf_executor.graph` verifier will reject any
    unknown operation. In order to execute standard `tf` dialect operations
    (like `tf.Add`) they must be wrapped in the `tf_executor.island` operation.

    The `tf_executor.graph` operation does not accept any operands, inputs are
    implicitly captured by the region, representing the feeds to the graph.

    The region attached to `tf_executor.graph` is terminated by a
    `tf_executor.fetch` operation. The operands of the terminator correspond to
    the result values (or fetches) of the `tf_executor.graph` operation. The
    behavior is undefined if any of the operands of the `tf_executor.fetch` is
    dead.

#### Results:

| Result | Description |
| :----: | ----------- |
`results` | any type

### `tf_executor.island` (::mlir::tf_executor::IslandOp)


    The `tf_executor.island` operation is a wrapper for operations in other
    dialects to be nested in a `tf_executor.graph`.
  


    The `tf_executor.graph` operation does not allow `tf` dialect operations to
    be immediately nested underneath it. The `tf_executor.island` is introduced
    as a wrapper for `tf` dialect operations: this results in a more consistent
    representation which makes analysis and transformation simpler.
    The `tf_executor.island` operation has a single region with a single block
    attached (only functional control flow is allowed). The block is terminated
    by a `tf_executor.yield` operation. The operands of the terminator
    correspond to the result values of the `tf_executor.island` operation. An
    extra result of type `!tf_executor.control` is always produced by every
    `tf_executor.island`.
    Within an island, execution semantics follow standard sequential behavior as
    expected by TF2 and by compiler analyses and transformations, and values
    can’t be dead. Other nested `tf_executor.graph` operations can be present in
    the region to re-enable the TensorFlow executor for a subsection of the
    code.
     - Initially the functional control flow operations are calling functions
       involving graphs, if `tf_executor.graph` weren’t allowed in an island,
       these operations would need to have an equivalent in the `tf_executor`
       dialect to be modelled in a graph.
     - Nesting also allows forming islands without involving inter-procedural
       analyses: any function call may involve a callee with a graph.
    The `tf_executor.island` region allows implicit capture. If any value
    captured by a `tf_executor.island` is dead, the whole region does not
    execute and every produced value is marked as dead as well.
    An arbitrary number of `tf_executor.control` operands are accepted by a
    `tf_executor.island` operation.
    If any operand or implicitly captured value are dead, the region is not
    executed and dead values are immediately returned for every result.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`outputs` | any type
`control` | control

### `tf_executor.LoopCond` (::mlir::tf_executor::LoopCondOp)


    The "tf_executor.LoopCond" operation forwards a boolean value as loop
    condition of Tensorflow while loops.
  


    More details can be found in Tensorflow Control Flow white paper:
    https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

    This is defined in Tensorflow as:

    REGISTER_OP("LoopCond")
       .Input("input: bool")
       .Output("output: bool")

    For example:
      %5:2 = tf_executor.LoopCond %4#0 {name: "while/LoopCond"}

    Note: Additional result corresponds to the control output.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | tensor of 1-bit signless integer values
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | tensor of 1-bit signless integer values
`control` | control

### `tf_executor.Merge` (::mlir::tf_executor::MergeOp)


    The "tf_executor.Merge" operation takes a list of input operands and returns
    a value of the operand type along with the index of the first match encountered.
  


    More details can be found in Tensorflow Control Flow white paper:
    https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

    This is defined in TensorFlow as:

    REGISTER_OP("Merge")
       .Input("inputs: N * T")
       .Output("output: T")
       .Output("value_index: int32")

    For example:
      %2 = tf_executor.Merge %0, %1, %2, %3 : tensor<*xf32>

    Note: Additional result corresponds to the control output.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`inputs_and_control` | any type

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | tensor of any type values
`value_index` | tensor of 32-bit signless integer values
`control` | control

### `tf_executor.NextIteration.Sink` (::mlir::tf_executor::NextIterationSinkOp)


    The "tf_executor.NextIteration.Sink" is paired with a
    "tf_executor.NextIteration.source" to represent NextIteration op in
    Tensorflow.
  


Syntax:

```
operation ::= `tf_executor.NextIteration.Sink` `[` $token `]` $input (`,` $controlInputs^)? `:` type($input) attr-dict
```


    Tensorflow NextIteration operation forwards its input to the next iteration
    of a while loop. Each loop variable needs its own NextIteration op.

    More details can be found in Tensorflow Control Flow white paper:
    https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

    In the TF executor dialect, the NextIteration op is broken into
    tf_executor.NextIteration.sink and tf_executor.NextIteration.source because
    NextIteration is a back-edge in Tensorflow graph, which would form a data
    flow cycle if expressed naively in a basic block.
    tf_executor.NextIteration.source takes no input but returns results while
    tf_executor.NextIteration.sink takes input but doesn't return anything. When
    optimizing these ops, they are paired by token and considered as a single
    op.

    This is defined in Tensorflow as:

    REGISTER_OP("NextIteration")
       .Input("data: T")
       .Output("output: T")
       .Attr("T: type")

    For example:
      %value, %token, %ctl = tf_executor.NextIteration.Source : tensor<*xi32>
      tf_executor.NextIteration.sink [%token] (%value) : tensor<*xi32>

    Note: Additional result corresponds to the control output.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`token` | token
`input` | any type
`controlInputs` | control

### `tf_executor.NextIteration.Source` (::mlir::tf_executor::NextIterationSourceOp)


    The "tf_executor.NextIteration.Source" is paired with a
    "tf_executor.NextIteration.sink" to represent NextIteration op in
    Tensorflow.
  


Syntax:

```
operation ::= `tf_executor.NextIteration.Source` `:` type($output) attr-dict
```


    Tensorflow NextIteration operation forwards its input to the next iteration
    of a while loop. Each loop variable needs its own NextIteration op.

    More details can be found in Tensorflow Control Flow white paper:
    https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

    In the TF executor dialect, the NextIteration op is broken into
    tf_executor.NextIteration.sink and tf_executor.NextIteration.source because
    NextIteration is a back-edge in Tensorflow graph, which would form a data
    flow cycle if expressed naively in a basic block.
    tf_executor.NextIteration.source takes no input but returns results while
    tf_executor.NextIteration.sink takes input but doesn't return anything. When
    optimizing these ops, they are paired by token and considered as a single
    op.

    This is defined in Tensorflow as:

    REGISTER_OP("NextIteration")
       .Input("data: T")
       .Output("output: T")
       .Attr("T: type")

    For example:
      %value, %token, %ctl = tf_executor.NextIteration.Source : tensor<*xi32>
      tf_executor.NextIteration.sink [%token] (%value) : tensor<*xi32>

    Note: Additional result corresponds to the control output.

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | any type
`token` | token
`control` | control

### `tf_executor._SwitchN` (::mlir::tf_executor::SwitchNOp)


    The "tf_executor._SwitchN" operation takes two inputs, `data` and `index`
    and an integer attribute `num_outs` indicating the number of outputs. The
    `data` input is copied to output indicated by the `index` input. The other
    outputs are marked as dead. If one of the inputs or a control token is
    dead, then all of the outputs are marked as dead as well.
  


    This is defined in TensorFlow as:

    REGISTER_OP("_SwitchN")
        .Input("data: T")
        .Input("output_index: int32")
        .Output("outputs: num_outs * T")
        .Attr("num_outs: int >= 1")
        .Attr("T: type")
        .SetShapeFn(SwitchNShape);

    For example:
      %2:6 = tf_executor.SwitchN %0, %1 of 5 : tensor<??xf32>

    Note: One additional result corresponds to the control output.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`num_outs` | ::mlir::IntegerAttr | 64-bit signless integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`data` | any type
`index` | tensor of 32-bit signless integer values
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`outputs` | any type
`control` | control

### `tf_executor.Switch` (::mlir::tf_executor::SwitchOp)


    The "tf_executor.Switch" operation takes a data operand and a boolean
    predicate condition, and returns two values matching the type of the data
    predicate.
  


    More details can be found in Tensorflow Control Flow white paper:
    https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

    This is defined in TensorFlow as:

    REGISTER_OP("Switch")
       .Input("data: T")
       .Input("pred: bool")
       .Output("output_false: T")
       .Output("output_true: T")

    For example:
      %2 = tf_executor.Switch %0, %1 : tensor<*xf32>

    Note: Additional result corresponds to the control output.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`data` | any type
`predicate` | tensor of 1-bit signless integer values
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`falseOutput` | any type
`trueOutput` | any type
`control` | control

### `tf_executor.yield` (::mlir::tf_executor::YieldOp)


    The `tf_executor.yield` operation terminates and returns values for the
    `tf_executor.island` operation.
  


Syntax:

```
operation ::= `tf_executor.yield` ($fetches^ `:` type($fetches))? attr-dict
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`fetches` | any type

