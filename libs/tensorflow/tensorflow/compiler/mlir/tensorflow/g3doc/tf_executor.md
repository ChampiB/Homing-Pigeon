<!-- Autogenerated by mlir-tblgen; don't manually edit -->
# 'tf_executor' Dialect

The TensorFlow Executor dialect.

This dialect models the TensorFlow executor semantics and can represent
arbitrary TensorFlow graphs. As such it follows the existing execution model
that includes deadness propagation, concurrent semantics, and control
dependencies.

Operations in this dialect return a value of type `!tf_executor.control` as
last returned value (exceptions are `tf_executor.NextIteration.graph`,
`tf_executor.NextIteration.sink` and `tf_executor.fetch` which don’t return any
value).

[TOC]

## Operation definition

### `tf_executor.ControlTrigger` (::mlir::tf_executor::ControlTriggerOp)


    The `tf_executor.ControlTrigger` operation is similar to a no-op except that
    it always produces a valid output even when inputs are dead.
  


Syntax:

```
operation ::= `tf_executor.ControlTrigger` $controlInputs attr-dict
```

Its primary use so far is in the scheduling of recvs, where we add
ControlTrigger nodes and use them to trigger recvs. We allow ControlTrigger
nodes to be enabled by dead nodes.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`control` | control

### `tf_executor.Enter` (::mlir::tf_executor::EnterOp)


    The "tf_executor.Enter" operation forwards its input to Tensorflow while
    loop.
  

More details can be found in Tensorflow Control Flow white paper:
https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

Each tensor needs its own tf_executor.Enter to be made available inside a
while loop.

This is defined in Tensorflow as:

REGISTER_OP("Enter")
   .Input("data: T")
   .Output("output: T")
   .Attr("T: type")
   .Attr("frame_name: string")
   .Attr("is_constant: bool = false")
   .Attr("parallel_iterations: int = 10")

For example:
   %res:2 = tf_executor.Enter %arg0 frame "some/frame" parallel_iterations 42 constant : tensor<*xf32>

Note: Additional result corresponds to the control output.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`frame_name` | ::mlir::StringAttr | string attribute
`is_constant` | ::mlir::BoolAttr | bool attribute
`parallel_iterations` | ::mlir::IntegerAttr | 64-bit signless integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`data` | any type
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | any type
`control` | control

### `tf_executor.Exit` (::mlir::tf_executor::ExitOp)


    The "tf_executor.Exit" operation forwards a value from an while loop to its
    consumer outside of loop. Each returned tensor needs its own
    tf_executor.Exit.
  

More details can be found in Tensorflow Control Flow white paper:
https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

This is defined in Tensorflow as:

REGISTER_OP("Exit")
   .Input("data: T")
   .Output("output: T")
   .Attr("T: type")

For example:
 %1:2 = tf_executor.Exit %0#0 : tensor<*xi32> {T: "tfdtype$DT_INT32"}

Note: Additional result corresponds to the control output.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`data` | any type
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | any type
`control` | control

### `tf_executor.fetch` (::mlir::tf_executor::FetchOp)


    The `tf_executor.fetch` operation terminates the graph and returns values;
  


Syntax:

```
operation ::= `tf_executor.fetch` ($fetches^ `:` type($fetches))? attr-dict
```

The non-control operands of the fetch operation are returned outside of the
graph and must match the return type of the graph.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`fetches` | any type

### `tf_executor.graph` (::mlir::tf_executor::GraphOp)

The `tf_executor.graph` operation contains a region with a
    single block that lists the operations in a TensorFlow graph.

The operations are topologically sorted in-order (no cycles are allowed in
the values). The execution model for operations in this block follows the
TensorFlow executor semantics:
  1. Operations that don’t have any transitive dependencies through the
     def/use chains may be executed in parallel
     (`tf_executor.NextIteration.Source` is the exception).
  2. SSA values in this block can be implicitly dead. This means that every
     SSA value defined in a `tf_executor.graph` can be considered implicitly
     wrapped in a conceptual `dead_or<T>` structure, and includes a runtime
     flag indicating if the value is dead or present.
  3. Operations may have special case handling of dead values.

The `tf_executor.graph` op only allows specific `tf_executor` dialect
operations in its body: the `tf_executor.graph` verifier will reject any
unknown operation. In order to execute standard `tf` dialect operations
(like `tf.Add`) they must be wrapped in the `tf_executor.island` operation.

The `tf_executor.graph` operation does not accept any operands, inputs are
implicitly captured by the region, representing the feeds to the graph.

The region attached to `tf_executor.graph` is terminated by a
`tf_executor.fetch` operation. The operands of the terminator correspond to
the result values (or fetches) of the `tf_executor.graph` operation. The
behavior is undefined if any of the operands of the `tf_executor.fetch` is
dead.

#### Results:

| Result | Description |
| :----: | ----------- |
`results` | any type

### `tf_executor.island` (::mlir::tf_executor::IslandOp)


    The `tf_executor.island` operation is a wrapper for operations in other
    dialects to be nested in a `tf_executor.graph`.
  

The `tf_executor.graph` operation does not allow `tf` dialect operations to
be immediately nested underneath it. The `tf_executor.island` is introduced
as a wrapper for `tf` dialect operations: this results in a more consistent
representation which makes analysis and transformation simpler.
The `tf_executor.island` operation has a single region with a single block
attached (only functional control flow is allowed). The block is terminated
by a `tf_executor.yield` operation. The operands of the terminator
correspond to the result values of the `tf_executor.island` operation. An
extra result of type `!tf_executor.control` is always produced by every
`tf_executor.island`.
Within an island, execution semantics follow standard sequential behavior as
expected by TF2 and by compiler analyses and transformations, and values
can’t be dead. Other nested `tf_executor.graph` operations can be present in
the region to re-enable the TensorFlow executor for a subsection of the
code.
 - Initially the functional control flow operations are calling functions
   involving graphs, if `tf_executor.graph` weren’t allowed in an island,
   these operations would need to have an equivalent in the `tf_executor`
   dialect to be modelled in a graph.
 - Nesting also allows forming islands without involving inter-procedural
   analyses: any function call may involve a callee with a graph.
The `tf_executor.island` region allows implicit capture. If any value
captured by a `tf_executor.island` is dead, the whole region does not
execute and every produced value is marked as dead as well.
An arbitrary number of `tf_executor.control` operands are accepted by a
`tf_executor.island` operation.
If any operand or implicitly captured value are dead, the region is not
executed and dead values are immediately returned for every result.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`outputs` | any type
`control` | control

### `tf_executor.LoopCond` (::mlir::tf_executor::LoopCondOp)


    The "tf_executor.LoopCond" operation forwards a boolean value as loop
    condition of Tensorflow while loops.
  

More details can be found in Tensorflow Control Flow white paper:
https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

This is defined in Tensorflow as:

REGISTER_OP("LoopCond")
   .Input("input: bool")
   .Output("output: bool")

For example:
  %5:2 = tf_executor.LoopCond %4#0 {name: "while/LoopCond"}

Note: Additional result corresponds to the control output.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | tensor of 1-bit signless integer values
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | tensor of 1-bit signless integer values
`control` | control

### `tf_executor.Merge` (::mlir::tf_executor::MergeOp)


    The "tf_executor.Merge" operation takes a list of input operands and returns
    a value of the operand type along with the index of the first match encountered.
  

More details can be found in Tensorflow Control Flow white paper:
https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

This is defined in TensorFlow as:

REGISTER_OP("Merge")
   .Input("inputs: N * T")
   .Output("output: T")
   .Output("value_index: int32")

For example:
  %2 = tf_executor.Merge %0, %1, %2, %3 : tensor<*xf32>

Note: Additional result corresponds to the control output.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`inputs_and_control` | any type

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | tensor of any type values
`value_index` | tensor of 32-bit signless integer values
`control` | control

### `tf_executor.NextIteration.Sink` (::mlir::tf_executor::NextIterationSinkOp)


    The "tf_executor.NextIteration.Sink" is paired with a
    "tf_executor.NextIteration.source" to represent NextIteration op in
    Tensorflow.
  


Syntax:

```
operation ::= `tf_executor.NextIteration.Sink` `[` $token `]` $input (`,` $controlInputs^)? `:` type($input) attr-dict
```

Tensorflow NextIteration operation forwards its input to the next iteration
of a while loop. Each loop variable needs its own NextIteration op.

More details can be found in Tensorflow Control Flow white paper:
https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

In the TF executor dialect, the NextIteration op is broken into
tf_executor.NextIteration.sink and tf_executor.NextIteration.source because
NextIteration is a back-edge in Tensorflow graph, which would form a data
flow cycle if expressed naively in a basic block.
tf_executor.NextIteration.source takes no input but returns results while
tf_executor.NextIteration.sink takes input but doesn't return anything. When
optimizing these ops, they are paired by token and considered as a single
op.

This is defined in Tensorflow as:

REGISTER_OP("NextIteration")
   .Input("data: T")
   .Output("output: T")
   .Attr("T: type")

For example:
  %value, %token, %ctl = tf_executor.NextIteration.Source : tensor<*xi32>
  tf_executor.NextIteration.sink [%token] (%value) : tensor<*xi32>

Note: Additional result corresponds to the control output.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`token` | token
`input` | any type
`controlInputs` | control

### `tf_executor.NextIteration.Source` (::mlir::tf_executor::NextIterationSourceOp)


    The "tf_executor.NextIteration.Source" is paired with a
    "tf_executor.NextIteration.sink" to represent NextIteration op in
    Tensorflow.
  


Syntax:

```
operation ::= `tf_executor.NextIteration.Source` `:` type($output) attr-dict
```

Tensorflow NextIteration operation forwards its input to the next iteration
of a while loop. Each loop variable needs its own NextIteration op.

More details can be found in Tensorflow Control Flow white paper:
https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

In the TF executor dialect, the NextIteration op is broken into
tf_executor.NextIteration.sink and tf_executor.NextIteration.source because
NextIteration is a back-edge in Tensorflow graph, which would form a data
flow cycle if expressed naively in a basic block.
tf_executor.NextIteration.source takes no input but returns results while
tf_executor.NextIteration.sink takes input but doesn't return anything. When
optimizing these ops, they are paired by token and considered as a single
op.

This is defined in Tensorflow as:

REGISTER_OP("NextIteration")
   .Input("data: T")
   .Output("output: T")
   .Attr("T: type")

For example:
  %value, %token, %ctl = tf_executor.NextIteration.Source : tensor<*xi32>
  tf_executor.NextIteration.sink [%token] (%value) : tensor<*xi32>

Note: Additional result corresponds to the control output.

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | any type
`token` | token
`control` | control

### `tf_executor._SwitchN` (::mlir::tf_executor::SwitchNOp)


    The "tf_executor._SwitchN" operation takes two inputs, `data` and `index`
    and an integer attribute `num_outs` indicating the number of outputs. The
    `data` input is copied to output indicated by the `index` input. The other
    outputs are marked as dead. If one of the inputs or a control token is
    dead, then all of the outputs are marked as dead as well.
  

This is defined in TensorFlow as:

REGISTER_OP("_SwitchN")
    .Input("data: T")
    .Input("output_index: int32")
    .Output("outputs: num_outs * T")
    .Attr("num_outs: int >= 1")
    .Attr("T: type")
    .SetShapeFn(SwitchNShape);

For example:
  %2:6 = tf_executor.SwitchN %0, %1 of 5 : tensor<??xf32>

Note: One additional result corresponds to the control output.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`num_outs` | ::mlir::IntegerAttr | 64-bit signless integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`data` | any type
`index` | tensor of 32-bit signless integer values
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`outputs` | any type
`control` | control

### `tf_executor.Switch` (::mlir::tf_executor::SwitchOp)


    The "tf_executor.Switch" operation takes a data operand and a boolean
    predicate condition, and returns two values matching the type of the data
    predicate.
  

More details can be found in Tensorflow Control Flow white paper:
https://storage.googleapis.com/download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf

This is defined in TensorFlow as:

REGISTER_OP("Switch")
   .Input("data: T")
   .Input("pred: bool")
   .Output("output_false: T")
   .Output("output_true: T")

For example:
  %2 = tf_executor.Switch %0, %1 : tensor<*xf32>

Note: Additional result corresponds to the control output.

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`data` | any type
`predicate` | tensor of 1-bit signless integer values
`controlInputs` | control

#### Results:

| Result | Description |
| :----: | ----------- |
`falseOutput` | any type
`trueOutput` | any type
`control` | control

### `tf_executor.yield` (::mlir::tf_executor::YieldOp)


    The `tf_executor.yield` operation terminates and returns values for the
    `tf_executor.island` operation.
  


Syntax:

```
operation ::= `tf_executor.yield` ($fetches^ `:` type($fetches))? attr-dict
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`fetches` | any type

